{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modular_nmf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalties vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import activation_learner, plot\n",
    "import librosa\n",
    "import itertools\n",
    "\n",
    "FS = 22050\n",
    "input_paths = [\"linear-mix-1.wav\", \"linear-mix-2.wav\", \"linear-mix.wav\"]\n",
    "inputs = [librosa.load(path, sr=FS)[0] for path in input_paths]\n",
    "\n",
    "OVERLAP_FACTOR = 4\n",
    "HOP_SIZE = 1\n",
    "BETA = 0\n",
    "NMELS = 256\n",
    "# stop conditions\n",
    "ITER_MAX = 500\n",
    "# logging\n",
    "DIVERGENCE = modular_nmf.BetaDivergence(0)\n",
    "PENALTIES = [\n",
    "    modular_nmf.L1(),\n",
    "    modular_nmf.L2(),\n",
    "    modular_nmf.SmoothGain(),\n",
    "    modular_nmf.SmoothDiago(),\n",
    "    modular_nmf.VirtanenTemporalContinuity(),\n",
    "]\n",
    "LAMBDAS = [1, 10, 100, 1e4,1e6]\n",
    "for penalty in PENALTIES:\n",
    "    fig, axs = plt.subplots(2, len(LAMBDAS))\n",
    "    fig.set_size_inches(20, 10)\n",
    "    fig.suptitle(f\"{penalty.__class__.__name__}\")\n",
    "\n",
    "    for p, lambda_ in enumerate(LAMBDAS):\n",
    "        learner = activation_learner.ActivationLearner(\n",
    "            inputs,\n",
    "            fs=FS,\n",
    "            n_mels=NMELS,\n",
    "            win_size=HOP_SIZE * OVERLAP_FACTOR,\n",
    "            hop_size=HOP_SIZE,\n",
    "            divergence=DIVERGENCE,\n",
    "            penalties=[(penalty, lambda_)],\n",
    "            postprocessors=[],\n",
    "        )\n",
    "        losses = []\n",
    "        for i in itertools.count():\n",
    "            try:\n",
    "                loss, loss_comp = learner.iterate(0)\n",
    "            except:\n",
    "                print(f\"Stopped at iter {i} due to error\")\n",
    "                raise\n",
    "            losses.append(loss_comp)\n",
    "\n",
    "            if i > ITER_MAX:\n",
    "                print(f\"Stopped at NMF iteration={i} loss={loss}\")\n",
    "                break\n",
    "        plot.plot_H(learner.H, learner.split_idx, ax=axs[0, p])\n",
    "        axs[0, p].set_title(f\"{lambda_:.2e}\")\n",
    "        plot.plot_loss_history(losses, ax=axs[1, p])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
