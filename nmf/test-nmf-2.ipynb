{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import soundfile\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from pprint import pprint\n",
    "import scipy.ndimage\n",
    "import scipy.signal\n",
    "import logging\n",
    "import itertools\n",
    "import scipy.sparse\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from unmixdb import UnmixDB\n",
    "from abcdj import ABCDJ\n",
    "import activation_learner, carve, plot, param_estimator, modular_nmf\n",
    "from common import dense_to_sparse, sparse_to_dense\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = 22050\n",
    "# T = np.linspace(0, 10, 10 * FS)\n",
    "# inputs = [\n",
    "# 0.01 * np.sin(2 * np.pi * 200 * T**2),\n",
    "# np.sin(2 * np.pi * 200 * (T)**2) * np.linspace(0, 1, len(T)),\n",
    "# ]\n",
    "input_paths = [\"linear-mix-1.wav\", \"linear-mix-2.wav\", \"linear-mix.wav\"]\n",
    "inputs = [librosa.load(path, sr=FS)[0] for path in input_paths]\n",
    "\n",
    "FS = 22050\n",
    "HOP_SIZES = [2.0, 0.1]\n",
    "OVERLAP_FACTOR = 1\n",
    "CARVE_THRESHOLD_DB = -60\n",
    "NMELS = 256\n",
    "DIVERGENCE = modular_nmf.BetaDivergence(0)\n",
    "PENALTIES = [\n",
    "    (modular_nmf.SmoothDiago(), 216),\n",
    "    (modular_nmf.L1(), 23),\n",
    "    (modular_nmf.L2(), 823),\n",
    "    (modular_nmf.SmoothGain(), 23),\n",
    "]\n",
    "POSTPROCESSORS = [\n",
    "    # (modular_nmf.PolyphonyLimit(1), 0.1)\n",
    "]\n",
    "PP_STRENGTH = 0\n",
    "LOW_POWER_FACTOR = 2e-2\n",
    "# stop conditions\n",
    "DLOSS_MIN = 1e-7\n",
    "LOSS_MIN = -np.inf\n",
    "ITER_MAX = 3000\n",
    "## other stuff\n",
    "# logging\n",
    "PLOT_NMF_EVERY = 600\n",
    "LOG_NMF_EVERY = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi pass NMF\n",
    "previous_H = None\n",
    "previous_split_idx = None\n",
    "for hop_size in HOP_SIZES:\n",
    "    win_size = OVERLAP_FACTOR * hop_size\n",
    "    logger.info(f\"Starting round with {hop_size=}s, {win_size=}s\")\n",
    "\n",
    "    learner = activation_learner.ActivationLearner(\n",
    "        inputs,\n",
    "        fs=FS,\n",
    "        n_mels=NMELS,\n",
    "        win_size=win_size,\n",
    "        hop_size=hop_size,\n",
    "        divergence=DIVERGENCE,\n",
    "        penalties=PENALTIES,\n",
    "        postprocessors=POSTPROCESSORS,\n",
    "        low_power_factor=LOW_POWER_FACTOR,\n",
    "    )\n",
    "\n",
    "    # carve and resize H from previous round\n",
    "    if previous_H is not None:\n",
    "        H_carved = carve.carve(previous_H, previous_split_idx, CARVE_THRESHOLD_DB)\n",
    "        H_carved_resized = carve.resize_cv_area(H_carved, learner.H.shape)\n",
    "        plot.plot_carve_resize(H_carved, H_carved_resized)\n",
    "        plt.show()\n",
    "\n",
    "        learner._H = dense_to_sparse(H_carved_resized)\n",
    "\n",
    "    # iterate\n",
    "    logger.info(\"Running NMF\")\n",
    "    last_loss = np.inf\n",
    "    loss_history = []\n",
    "    for i in itertools.count():\n",
    "        loss, loss_components = learner.iterate(PP_STRENGTH)\n",
    "        dloss = abs(last_loss - loss)\n",
    "        last_loss = loss\n",
    "        loss_history.append(loss_components)\n",
    "\n",
    "        if i % LOG_NMF_EVERY == 0:\n",
    "            logger.info(f\"NMF iteration={i} loss={loss:.2e} dloss={dloss:.2e}\")\n",
    "        if dloss < DLOSS_MIN or np.sum(loss) < LOSS_MIN or i > ITER_MAX:\n",
    "            logger.info(f\"Stopped at NMF iteration={i} loss={loss} dloss={dloss}\")\n",
    "            break\n",
    "        if i % PLOT_NMF_EVERY == 0:\n",
    "            plot.plot_nmf(learner)\n",
    "            plt.show()\n",
    "\n",
    "    previous_H = learner.H\n",
    "    previous_split_idx = learner.split_idx\n",
    "\n",
    "# plot NMF\n",
    "plot.plot_nmf(learner)\n",
    "plt.show()\n",
    "\n",
    "# plot loss history\n",
    "plot.plot_loss_history(loss_history)\n",
    "plt.show()\n",
    "\n",
    "# get ground truth\n",
    "tau = np.arange(0, learner.V.shape[1]) * hop_size\n",
    "\n",
    "GAIN_ESTOR = param_estimator.GainEstimator.SUM\n",
    "WARP_ESTOR = param_estimator.WarpEstimator.CENTER_OF_MASS\n",
    "\n",
    "# estimate gain\n",
    "logger.info(f\"Estimating gain with method {GAIN_ESTOR}\")\n",
    "est_gain = GAIN_ESTOR.value(learner)\n",
    "plot.plot_gain(tau, est_gain)\n",
    "plt.show()\n",
    "\n",
    "# estimate warp\n",
    "logger.info(f\"Estimating warp with method {WARP_ESTOR}\")\n",
    "est_warp = WARP_ESTOR.value(learner, hop_size)\n",
    "fig = plt.figure()\n",
    "plot.plot_warp(tau, est_warp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
