{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "USE_GPU = False\n",
    "\n",
    "if USE_GPU:\n",
    "    import manage_gpus as gpl\n",
    "\n",
    "    gpl.get_gpu_lock()\n",
    "import activation_learner\n",
    "import pytorch_nmf\n",
    "import param_estimator\n",
    "import plot\n",
    "from mixes.unmixdb import UnmixDB\n",
    "from mixes.synthetic import SyntheticDB\n",
    "import carve\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = UnmixDB(\n",
    "    \"/data2/anasynth_nonbp/schwarz/abc-dj/data/unmixdb-zenodo/\"\n",
    ")  # inverno\n",
    "# dataset = UnmixDB(\"/data2/anasynth_nonbp/andre/unmixdb-zenodo\") # guqin\n",
    "# dataset = SyntheticDB()\n",
    "FS = 22050\n",
    "mix = dataset.mixes[16]\n",
    "# mix = dataset.mixes[1]\n",
    "logger = logging.getLogger(mix.name)\n",
    "logging.basicConfig()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.info(mix.name)\n",
    "\n",
    "inputs = [track.audio for track in mix.tracks] + [mix.audio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hops = [4,1, 0.5, 0.1]\n",
    "overlap = 8\n",
    "nmels = 128\n",
    "low_power_threshold = 0.01\n",
    "spec_power = 2\n",
    "learners: list[activation_learner.ActivationLearner] = []\n",
    "\n",
    "for hop_size in hops:\n",
    "    win_size = hop_size * overlap\n",
    "    divergence = pytorch_nmf.BetaDivergence(0)\n",
    "    penalties = (\n",
    "        [\n",
    "            # (pytorch_nmf.L1(), 1e-1),\n",
    "            # (pytorch_nmf.SmoothDiago(), 0.0638),\n",
    "            # (pytorch_nmf.SmoothOverCol(), 0.00034),\n",
    "            # (pytorch_nmf.SmoothOverRow(), 0.00171),\n",
    "            # (pytorch_nmf.Lineness(), 1e8),\n",
    "        ]\n",
    "        if hop_size == hops[-1]\n",
    "        else []\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Starting round with {hop_size=}s, {win_size=}s\")\n",
    "\n",
    "    learner = activation_learner.ActivationLearner(\n",
    "        inputs,\n",
    "        fs=FS,\n",
    "        n_mels=nmels,\n",
    "        win_size=win_size,\n",
    "        hop_size=hop_size,\n",
    "        penalties=penalties,\n",
    "        divergence=divergence,\n",
    "        low_power_threshold=low_power_threshold,\n",
    "        use_gpu=USE_GPU,\n",
    "        spec_power=spec_power,\n",
    "        stft_win_func=\"barthann\",\n",
    "    )\n",
    "\n",
    "    # carve and resize H from previous round\n",
    "    if len(learners) > 0:\n",
    "        new_H = carve.resize_then_carve(\n",
    "            learners[-1].H,\n",
    "            learner.H.shape,\n",
    "            learners[-1].split_idx,\n",
    "            1e-3,\n",
    "            3,\n",
    "            diag_size=2,\n",
    "            max_slope=2,\n",
    "            n_filters=7,\n",
    "        )\n",
    "        plt.figure(\"H after resizing and carving\")\n",
    "        plot.plot_H(new_H.cpu().detach().numpy())\n",
    "        plt.show()\n",
    "\n",
    "        learner.H = new_H\n",
    "\n",
    "    loss_history = learner.fit(2000, dloss_min=1e-8)\n",
    "\n",
    "    torch.save(learner.H, f\"H_{hop_size:.2f}.torch\")\n",
    "    plot.plot_nmf(learner)\n",
    "    plt.show()\n",
    "    fig = plt.figure()\n",
    "    plot.plot_loss_history(loss_history)\n",
    "    plt.show()\n",
    "\n",
    "    learners.append(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "import scipy.signal\n",
    "\n",
    "GAIN_ESTORS = [\n",
    "    param_estimator.GainEstimator.SUM,\n",
    "    param_estimator.GainEstimator.MAX,\n",
    "]\n",
    "WARP_ESTORS = [\n",
    "    param_estimator.WarpEstimator.CENTER_OF_MASS,\n",
    "    param_estimator.WarpEstimator.ARGMAX,\n",
    "]\n",
    "#############\n",
    "# estimations\n",
    "\n",
    "# get ground truth\n",
    "tau = np.arange(0, learner.V.shape[1]) * hop_size\n",
    "real_gain = mix.gain(tau)\n",
    "real_warp = mix.warp(tau)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(GAIN_ESTORS))\n",
    "fig.set_size_inches(5 * len(GAIN_ESTORS), 4)\n",
    "fig.suptitle(\"Gain estimation\")\n",
    "for i, estor in enumerate(GAIN_ESTORS):\n",
    "    est_gain = estor(learner.H, learner.split_idx, spec_power)\n",
    "    # est_gain = scipy.signal.savgol_filter(est_gain, 15, 3, axis=0)\n",
    "    err_gain = param_estimator.error(est_gain, real_gain)\n",
    "    plot.plot_gain(tau, est_gain, real_gain, ax=axes[i])\n",
    "    axes[i].set_title(f\"{estor.__name__} err={err_gain:.2e}\")\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(WARP_ESTORS))\n",
    "fig.set_size_inches(5 * len(WARP_ESTORS), 4)\n",
    "fig.suptitle(\"Warp estimation\")\n",
    "for i, estor in enumerate(WARP_ESTORS):\n",
    "    est_warp = estor(learner.H, learner.split_idx, hop_size)\n",
    "    # est_warp = scipy.signal.savgol_filter(est_warp, 15, 2, axis=0)\n",
    "    err_warp = param_estimator.error(est_warp, real_warp)\n",
    "    plot.plot_warp(tau, est_warp, real_warp, ax=axes[i])\n",
    "    axes[i].set_title(f\"{estor.__name__} err={err_warp:.2e}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(abs(est_gain - real_gain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "from IPython.display import Video, display\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylim(0, learner.H.detach().numpy().max())\n",
    "(line,) = ax.plot(learner.H[:, 0].detach().numpy(), \"x-\")\n",
    "\n",
    "\n",
    "def update(i):\n",
    "    line.set_ydata(learner.H[:, i].detach().numpy())\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, update, frames=range(learner.H.shape[1]), blit=True, interval=int(1000 / 30)\n",
    ")\n",
    "\n",
    "ani.save(\"animation.mp4\", writer=\"ffmpeg\")\n",
    "display(Video(\"animation.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
