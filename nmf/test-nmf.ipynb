{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import scipy.ndimage\n",
    "from IPython.display import display, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "from typing import Any, Callable, Tuple, Optional\n",
    "\n",
    "\n",
    "def beta_divergence(x: np.ndarray, y: np.ndarray, beta: float):\n",
    "    \"\"\"returns beta divergence\n",
    "\n",
    "    Args:\n",
    "        a (np.ndarray): first matrix\n",
    "        b (np.ndarray): second matrix\n",
    "        beta (float): beta parameter\n",
    "    \"\"\"\n",
    "\n",
    "    if beta == 0:\n",
    "        ret = x / y - np.log(x / y) - 1\n",
    "    elif beta == 1:\n",
    "        ret = x * (np.log(x) - np.log(y)) + (y - x)\n",
    "    else:\n",
    "        ret = (\n",
    "            (\n",
    "                np.power(x, beta)\n",
    "                + (beta - 1) * np.power(y, beta)\n",
    "                - beta * x * np.power(y, beta - 1)\n",
    "            )\n",
    "            / beta\n",
    "            / (beta - 1)\n",
    "        )\n",
    "    return np.sum(ret)\n",
    "\n",
    "\n",
    "def linear_warmup(epoch, epoch0, value0, epoch1, value1):\n",
    "    if epoch < epoch0:\n",
    "        return value0\n",
    "    elif epoch > epoch1:\n",
    "        return value1\n",
    "    return (epoch - epoch0) * (value1 - value0) / (epoch1 - epoch0)\n",
    "\n",
    "\n",
    "def gen_kernel(c: int):\n",
    "    kern = np.zeros((2 * c, 2 * c))\n",
    "    kern[c:, c:] = 1\n",
    "    kern[:c, :c] = 1\n",
    "    # kern = scipy.ndimage.gaussian_filter(kern,5)\n",
    "    return kern\n",
    "\n",
    "\n",
    "def nmf(\n",
    "    V: np.ndarray,\n",
    "    W_init: np.ndarray,\n",
    "    H_init: np.ndarray,\n",
    "    beta: float = 2,\n",
    "    n_epochs: int = 50,\n",
    "    polyphony_limit: Optional[int] = None,\n",
    "    continuous_len: Optional[int] = None,\n",
    "    warmup: Tuple[int, float, int, float] = (10, 0, 20, 1),\n",
    "):\n",
    "    assert not np.isnan(W_init).any(), \"W_init contains NaN\"\n",
    "    assert not np.isnan(H_init).any(), \"H_init contains NaN\"\n",
    "    assert np.all(W_init > 0), \"W_init is not positive\"\n",
    "    assert np.all(H_init > 0), \"H_init is not positive\"\n",
    "    eps = 1e-20\n",
    "    losses = []\n",
    "    regulation_strengths = []\n",
    "    Hs = []\n",
    "    H_s = []\n",
    "\n",
    "    W = W_init.copy()\n",
    "    H = H_init.copy()\n",
    "\n",
    "    if continuous_len is not None:\n",
    "        kernel = gen_kernel(continuous_len)\n",
    "        # kernel = np.eye(2*continuous_len)\n",
    "    pbar = tqdm(total=n_epochs)\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        dH = (W.T @ np.multiply(V, np.power(W @ H, beta - 2))) / (\n",
    "            W.T @ np.power(W @ H, beta - 1) + eps\n",
    "        )\n",
    "        assert not np.isnan(dH).any(), f\"NaN in dH at iter {i}\"\n",
    "        H *= dH\n",
    "        # dW = (np.multiply(V, np.power(W @ H, beta - 2)) @ H.T) / (\n",
    "        #     np.power(W @ H, beta - 1) @ H.T + eps\n",
    "        # )\n",
    "        # assert not np.isnan(dW).any(), f\"NaN in dW at iter {i}\"\n",
    "        # W *= dW\n",
    "\n",
    "        # regulation_strength = 1 - np.exp(-warmup_factor * i)\n",
    "        regulation_strength = linear_warmup(i, *warmup)\n",
    "        regulation_strengths.append(regulation_strength)\n",
    "\n",
    "        H_ = H.copy()\n",
    "\n",
    "        # 3.2 Restricting the number of simultaneous activations\n",
    "        if polyphony_limit is not None:\n",
    "            colCutoff = -np.partition(-H_, polyphony_limit, 0)[polyphony_limit, :]\n",
    "            H_[H_ < colCutoff[None, :]] = 0\n",
    "\n",
    "        # 3.3 Supporting time-continuous activations\n",
    "        if continuous_len is not None:\n",
    "            H_ = H_ * scipy.signal.convolve2d(H_, kernel, mode=\"same\")\n",
    "\n",
    "        H = (1 - regulation_strength) * H + regulation_strength * H_\n",
    "\n",
    "        H = np.clip(H, 0, 1)\n",
    "\n",
    "        Hs.append(H)\n",
    "        H_s.append(H_)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = beta_divergence(V, W @ H, beta)\n",
    "        assert not np.isnan(loss).any(), f\"NaN in loss at iter {i}\"\n",
    "        losses.append(loss)\n",
    "\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(f\"loss={loss:.2f}\")\n",
    "    return Hs, H_s, losses, regulation_strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = 22050\n",
    "NFFT = 1024\n",
    "HLEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = [\n",
    "    librosa.load(path, sr=FS)[0] for path in [\"linear-mix-1.wav\", \"linear-mix-2.wav\"]\n",
    "]\n",
    "mix, _ = librosa.load(\"linear-mix.wav\", sr=FS)\n",
    "print([i.shape for i in refs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ws = [np.abs(librosa.stft(ref, n_fft=NFFT, hop_length=HLEN)) for ref in refs]\n",
    "print([i.shape for i in Ws])\n",
    "W = np.concatenate(Ws, axis=1)\n",
    "print(W.shape)\n",
    "V = np.abs(librosa.stft(mix, n_fft=NFFT, hop_length=HLEN))\n",
    "# W = librosa.feature.melspectrogram(y=ref, sr=FS, n_fft=NFFT, hop_length=HLEN)\n",
    "# V = librosa.feature.melspectrogram(y=mix, sr=FS, n_fft=NFFT, hop_length=HLEN)\n",
    "\n",
    "W /= W.max()\n",
    "V /= V.max()\n",
    "\n",
    "W[W == 0] = 1e-50\n",
    "V[V == 0] = 1e-50\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(W))\n",
    "plt.show()\n",
    "librosa.display.specshow(librosa.amplitude_to_db(V))\n",
    "plt.show()\n",
    "print(W.shape)\n",
    "print(W.min(), W.max())\n",
    "print(V.shape)\n",
    "print(V.min(), V.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_init = np.random.rand(W.shape[1], V.shape[1])\n",
    "# H_init = np.zeros((W.shape[1], V.shape[1])) + 1e-30\n",
    "Hs, H_s, losses, regulation_strengths = nmf(\n",
    "    V,\n",
    "    W_init=W,\n",
    "    H_init=H_init,\n",
    "    beta=0.5,\n",
    "    n_epochs=100,\n",
    "    warmup=(10, 0, 100, 1),\n",
    "    polyphony_limit=None,\n",
    "    continuous_len=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def update_plot(epoch):\n",
    "    dilate = 30\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    plt.suptitle(f\"epoch {epoch}\")\n",
    "\n",
    "    plt.subplot(2, 3, 1)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(V))\n",
    "    plt.title(\"V\")\n",
    "\n",
    "    plt.subplot(2, 3, 2)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(W))\n",
    "    plt.title(\"W\")\n",
    "\n",
    "    ax1 = plt.subplot(2, 3, 3)\n",
    "\n",
    "    color = \"tab:red\"\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\", color=color)\n",
    "    ax1.plot(losses, color=color)\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color = \"tab:blue\"\n",
    "    ax2.set_ylabel(\"Regulation Strength\", color=color)\n",
    "    ax2.plot(regulation_strengths, color=color)\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "    ax1.plot(epoch, losses[epoch], \"x\", color=\"black\")\n",
    "    ax2.plot(epoch, regulation_strengths[epoch], \"x\", color=\"black\")\n",
    "\n",
    "    plt.title(\"Loss & Regulation Strength\")\n",
    "\n",
    "    plt.subplot(2, 3, 4)\n",
    "    # activation = scipy.ndimage.grey_dilation(Hs[epoch], (dilate, dilate))\n",
    "    activation = Hs[epoch]\n",
    "    plt.imshow(activation, origin=\"lower\")\n",
    "    plt.title(\"H\")\n",
    "\n",
    "    plt.subplot(2, 3, 5)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(W @ Hs[epoch]))\n",
    "    plt.title(\"V_hat\")\n",
    "\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.imshow(H_s[epoch], origin=\"lower\")\n",
    "    plt.title(\"H filtered\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "update_plot(len(Hs) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for i in range(len(Ws)):\n",
    "    plt.plot(Hs[-1][acc : acc + Ws[i].shape[1], :].sum(axis=0), label=f\"track {i}\")\n",
    "    acc += Ws[i].shape[1]\n",
    "plt.plot(Hs[-1].sum(axis=0), label=\"total\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title(\"estimated volume\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "\n",
    "hough, _, _ = skimage.transform.hough_line(Hs[-1])\n",
    "plt.imshow(hough, origin=\"lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
