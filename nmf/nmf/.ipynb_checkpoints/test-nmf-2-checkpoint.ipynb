{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import scipy.ndimage\n",
    "from IPython.display import display, Audio\n",
    "from activation_learner import ActivationLearner\n",
    "import scipy.signal\n",
    "import logging\n",
    "from unmixdb import UnmixDB\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"activation_learner\").setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def fade(a: np.ndarray, b: np.ndarray, l: int):\n",
    "    curve = np.linspace(0, 1, l)\n",
    "    a_fade = a[-l:] * (1 - curve)\n",
    "    b_fade = b[:l] * curve\n",
    "    return np.concatenate([a[:-l], a_fade + b_fade, b[l:]])\n",
    "\n",
    "\n",
    "def lowpass_filter(data, cutoff_freq, sampling_rate, order=1):\n",
    "    \"\"\"\n",
    "    Apply a 1st order lowpass filter to the data.\n",
    "\n",
    "    Parameters:\n",
    "    - data: numpy array containing the signal to be filtered\n",
    "    - cutoff_freq: cutoff frequency in Hz\n",
    "    - sampling_rate: sampling rate in Hz\n",
    "    - order: order of the filter\n",
    "\n",
    "    Returns:\n",
    "    - filtered_data: numpy array containing the filtered signal\n",
    "    \"\"\"\n",
    "    # Normalize the cutoff frequency\n",
    "    normal_cutoff = cutoff_freq / (0.5 * sampling_rate)\n",
    "\n",
    "    # Design the Butterworth filter\n",
    "    sos = scipy.signal.butter(\n",
    "        order, normal_cutoff, btype=\"low\", analog=False, output=\"sos\"\n",
    "    )\n",
    "\n",
    "    # Apply the filter to the data\n",
    "    filtered_data = scipy.signal.sosfilt(sos, data)\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audios\n",
    "\n",
    "FS = 22050\n",
    "ref_paths = [\"linear-mix-1.wav\", \"linear-mix-2.wav\"]\n",
    "mix_path = \"linear-mix.wav\"\n",
    "# ref_paths = [\"original.wav\"]\n",
    "# mix_path = \"original.wav\"\n",
    "# mix_path = \"boucled.wav\"\n",
    "# ref_paths = [\"amen.wav\", \"high.wav\"]\n",
    "# mix_path = \"nuttah.wav\"\n",
    "# ref_paths = [\"nuttah.wav\"]\n",
    "# mix_path= \"nuttah-timestretch.wav\"\n",
    "# refs = [librosa.load(i, sr=FS)[0] for i in ref_paths]\n",
    "# mix = librosa.load(mix_path, sr=FS)[0]\n",
    "\n",
    "## generate chirps\n",
    "# t = np.linspace(0, 2, int(2 * FS))\n",
    "# refs = [\n",
    "    # scipy.signal.chirp(t, 200, 2, 5000) + scipy.signal.chirp(t, 500, 2, 8000),\n",
    "    # scipy.signal.chirp(t, 4000, 2, 800) + scipy.signal.chirp(t, 8000, 2, f1=600),\n",
    "# ]\n",
    "# mix = fade(refs[0], refs[1], int(0.5 * FS))\n",
    "# mix += librosa.load(\"nuttah.wav\", sr=FS)[0][: len(mix)] * 1\n",
    "\n",
    "# mix += librosa.load(\"maya.wav\", sr=FS)[0][: len(mix)] * 0.3\n",
    "# mix /= mix.max()\n",
    "\n",
    "## load unmixdb\n",
    "unmixdb = UnmixDB(\"/data2/anasynth_nonbp/schwarz/abc-dj/data/unmixdb-zenodo\")\n",
    "mixes = dict(filter(lambda i: i[1].timestretch == \"stretch\", unmixdb.mixes.items()))\n",
    "x = list(mixes.values())[0]\n",
    "print(x)\n",
    "mix = x.audio(sr=FS)\n",
    "refs = [unmixdb.refsongs[track['name']].audio(sr=FS) for track in x.tracks]\n",
    "# ## alignment test\n",
    "# t = np.arange(FS) / FS\n",
    "# sig = np.concatenate(\n",
    "#     [\n",
    "#         np.sin(2 * np.pi * 2000 * t),\n",
    "#         np.sin(2 * np.pi * 4000 * t),\n",
    "#         np.sin(2 * np.pi * 6000 * t),\n",
    "#     ]\n",
    "# )\n",
    "# sig = scipy.signal.chirp(t, 800, t[-1], 2000)\n",
    "# refs = [sig]\n",
    "# mix = np.concatenate([np.ones(3 * FS) * 1e-50, sig])\n",
    "\n",
    "display(Audio(mix, rate=FS))\n",
    "for i, x in enumerate(refs):\n",
    "    print(i)\n",
    "    display(Audio(x, rate=FS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFFT = 1024\n",
    "HLEN = 256\n",
    "print(f\"{NFFT=} {HLEN=}\")\n",
    "\n",
    "model = ActivationLearner(\n",
    "    mix,\n",
    "    refs,\n",
    "    transform=lambda x: librosa.stft(x, n_fft=NFFT, hop_length=HLEN, center=True),\n",
    "    inv_transform=lambda S: librosa.istft(S, n_fft=NFFT, hop_length=HLEN, center=True),\n",
    "    # transform = lambda x: abs(librosa.cqt(x, sr=FS, hop_length=HLEN)),\n",
    "    # inv_transform=lambda S: librosa.icqt(S, sr=FS, hop_length=HLEN),\n",
    "    # transform = lambda x: abs(librosa.feature.mfcc(y=x, sr=FS)),\n",
    "    # inv_transform=lambda mfcc: librosa.feature.inverse.mfcc_to_audio(mfcc),\n",
    "    # transform = lambda x: librosa.feature.melspectrogram(y=x, sr=FS, n_fft=NFFT, hop_length=HLEN, power=1, n_mels=300),\n",
    "    # inv_transform = lambda S: librosa.feature.inverse.mel_to_audio(S, sr=FS, n_fft=NFFT, hop_length=HLEN, power=1, n_mels=300),\n",
    "    additional_dim=0,\n",
    ")\n",
    "losses = []\n",
    "for i in (pbar := tqdm(range(50))):\n",
    "    loss = model.iterate()\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(f\"loss={loss:.2e}\")\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"iter\")\n",
    "plt.title(\"distance\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMAP = \"turbo\"\n",
    "# Plot the H matrix\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 8))\n",
    "\n",
    "im = axes[0, 0].imshow(model.nmf.H, cmap=CMAP, aspect=\"auto\", origin=\"lower\")\n",
    "axes[0, 0].set_title(\"H (activations)\")\n",
    "axes[0, 0].set_xlabel(\"mix frame\")\n",
    "axes[0, 0].set_ylabel(\"ref frame\")\n",
    "fig.colorbar(im, ax=axes[0, 0])\n",
    "\n",
    "im = librosa.display.specshow(\n",
    "    librosa.power_to_db(model.nmf.W),\n",
    "    ax=axes[0, 1],\n",
    "    cmap=CMAP,\n",
    "    hop_length=HLEN,\n",
    "    n_fft=NFFT,\n",
    "    sr=FS,\n",
    "    x_axis=\"time\",\n",
    "    y_axis=\"fft\",\n",
    ")\n",
    "fig.colorbar(mappable=im, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"$W$ (reference tracks)\")\n",
    "\n",
    "for track, (a, b) in enumerate(zip(model.split_idx, model.split_idx[1:])):\n",
    "    axes[0, 0].axhline(a, color=\"r\", linestyle=\"--\")\n",
    "    axes[0, 0].annotate(f\"track {track}\", (0, (a + b) / 2), color=\"red\")\n",
    "    axes[0, 1].axvline(a / FS * HLEN, color=\"r\", linestyle=\"--\")\n",
    "    axes[0, 1].annotate(f\"track {track}\", ((a + b) / 2 / FS * HLEN, 1), color=\"red\")\n",
    "\n",
    "im = librosa.display.specshow(\n",
    "    librosa.power_to_db(model.nmf.V),\n",
    "    ax=axes[1, 0],\n",
    "    cmap=CMAP,\n",
    "    hop_length=HLEN,\n",
    "    n_fft=NFFT,\n",
    "    sr=FS,\n",
    "    x_axis=\"time\",\n",
    "    y_axis=\"fft\",\n",
    ")\n",
    "axes[1, 0].set_title(\"$V$ (mix)\")\n",
    "fig.colorbar(mappable=im, ax=axes[1, 0])\n",
    "\n",
    "im = librosa.display.specshow(\n",
    "    librosa.power_to_db(model.nmf.W @ model.nmf.H),\n",
    "    ax=axes[1, 1],\n",
    "    cmap=CMAP,\n",
    "    hop_length=HLEN,\n",
    "    n_fft=NFFT,\n",
    "    sr=FS,\n",
    "    x_axis=\"time\",\n",
    "    y_axis=\"fft\",\n",
    ")\n",
    "axes[1, 1].set_title(\"$\\hat{V} = WH$ (estimated mix)\")\n",
    "fig.colorbar(mappable=im, ax=axes[1, 1])\n",
    "\n",
    "colors = [\"blue\", \"green\", \"red\", \"cyan\", \"magenta\", \"yellow\", \"black\"]\n",
    "for i, v in enumerate(\n",
    "    iterable=model.position(threshold=5e-3, weiner=None, medfilt=None)\n",
    "):\n",
    "    axes[2, 0].plot(v, alpha=0.2, color=colors[i % len(colors)])\n",
    "for i, v in enumerate(iterable=model.position(threshold=5e-3)):\n",
    "    axes[2, 0].plot(v, label=f\"track {i}\", color=colors[i % len(colors)])\n",
    "axes[2, 0].legend()\n",
    "axes[2, 0].set_title(\"track time\")\n",
    "axes[2, 0].set_xlabel(\"ref frame\")\n",
    "axes[2, 0].set_ylabel(\"mix frame\")\n",
    "\n",
    "\n",
    "for i, v in enumerate(iterable=model.volume(weiner=None, medfilt=None)):\n",
    "    axes[2, 1].plot(v, alpha=0.2, color=colors[i % len(colors)])\n",
    "for i, v in enumerate(model.volume()):\n",
    "    axes[2, 1].plot(v, label=f\"track {i}\", color=colors[i % len(colors)])\n",
    "axes[2, 1].legend()\n",
    "axes[2, 1].set_title(\"track volume\")\n",
    "axes[2, 1].set_xlabel(\"mix frame\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "\n",
    "def estimate_tracks():\n",
    "    ret = []\n",
    "    for i in range(len(refs) + 1):\n",
    "        xi = model.reconstruct(i)\n",
    "        ret.append(xi)\n",
    "        print(\"track\", i)\n",
    "        display(Audio(xi, rate=FS))\n",
    "        sf.write(f\"estimated-{i}.wav\", xi / xi.max(), FS)\n",
    "    return ret\n",
    "\n",
    "\n",
    "estimates = estimate_tracks()\n",
    "# sdr, isr, sir, sar = museval.evaluate(\n",
    "#     np.expand_dims(np.vstack(refs), axis=-1),\n",
    "#     np.expand_dims(np.vstack(estimates), axis=-1),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
